{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook will get rid of class 1 photos and texts and then save all the data into pickle files for the training setp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import tensorlayer as tl\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = '102flowers' #\n",
    "need_256 = True # set to True for stackGAN\n",
    "\n",
    "\"\"\"\n",
    "images.shape = [8000, 64, 64, 3]\n",
    "captions_ids = [80000, any]\n",
    "\"\"\"\n",
    "cwd = os.getcwd()\n",
    "img_dir = os.path.join(cwd, '102flowers')\n",
    "caption_dir = os.path.join(cwd, 'text_c10')\n",
    "VOC_FIR = cwd + '/vocab.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## load captions\n",
    "caption_sub_dir = load_folder_list( caption_dir )\n",
    "captions_dict = {}\n",
    "processed_capts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00001',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00002',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00003',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00004',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00005',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00006',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00007',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00008',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00009',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00010',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00011',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00012',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00013',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00014',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00015',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00016',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00017',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00018',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00019',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00020',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00021',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00022',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00023',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00024',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00025',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00026',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00027',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00028',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00029',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00030',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00031',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00032',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00033',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00034',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00035',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00036',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00037',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00038',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00039',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00040',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00041',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00042',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00043',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00044',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00045',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00046',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00047',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00048',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00049',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00050',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00051',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00052',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00053',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00054',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00055',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00056',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00057',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00058',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00059',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00060',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00061',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00062',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00063',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00064',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00065',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00066',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00067',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00068',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00069',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00070',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00071',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00072',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00073',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00074',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00075',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00076',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00077',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00078',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00079',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00080',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00081',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00082',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00083',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00084',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00085',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00086',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00087',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00088',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00089',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00090',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00091',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00092',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00093',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00094',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00095',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00096',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00097',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00098',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00099',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00100',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00101',\n",
       " 'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00102']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_sub_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = \"C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00001'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[-5:len(test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      " * 8149 x 10 captions found \n"
     ]
    }
   ],
   "source": [
    "for sub_dir in caption_sub_dir: # get caption file list\n",
    "    # ignore if class 1\n",
    "    if sub_dir[-5:len(test)] == \"00001\":\n",
    "        print(\"passed\")\n",
    "        continue\n",
    "    with tl.ops.suppress_stdout():\n",
    "        files = tl.files.load_file_list(path=sub_dir, regx='^image_[0-9]+\\.txt')\n",
    "        for i, f in enumerate(files):\n",
    "            file_dir = os.path.join(sub_dir, f)\n",
    "            key = int(re.findall('\\d+', f)[0])\n",
    "            t = open(file_dir,'r')\n",
    "            lines = []\n",
    "            for line in t:\n",
    "                line = preprocess_caption(line)\n",
    "                lines.append(line)\n",
    "                processed_capts.append(tl.nlp.process_sentence(line, start_word=\"<S>\", end_word=\"</S>\"))\n",
    "            assert len(lines) == 10, \"Every flower image have 10 captions\"\n",
    "            captions_dict[key] = lines\n",
    "print(\" * %d x %d captions found \" % (len(captions_dict), len(lines)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8189 including class 1, 8149 without"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * 8149 x 10 captions found \n"
     ]
    }
   ],
   "source": [
    "print(\" * %d x %d captions found \" % (len(captions_dict), len(lines)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\jeff\\\\senior\\\\research\\\\text-to-image'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import h5py\n",
    "from PIL import Image\n",
    "os.path.join(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = h5py.File('C:\\\\jeff\\\\senior\\\\research\\\\text-to-image\\\\text_c10\\\\class_00001\\\\image_06734.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['txt1',\n",
       " 'txt10',\n",
       " 'txt2',\n",
       " 'txt3',\n",
       " 'txt4',\n",
       " 'txt5',\n",
       " 'txt6',\n",
       " 'txt7',\n",
       " 'txt8',\n",
       " 'txt9']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(f[\"txt10\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dset = f['txt1'][:]\n",
    "# img = Image.fromarray(dset.astype('uint8'), 'RGB')\n",
    "# img.save(\"class1/test.jpg\", \"JPEG\")\n",
    "# img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: vocab.txt already exists\n",
      "INFO:tensorflow:Initializing vocabulary from file: C:\\jeff\\senior\\research\\text-to-image/vocab.txt\n",
      "  [TL] Vocabulary from C:\\jeff\\senior\\research\\text-to-image/vocab.txt : <S> </S> <UNK>\n",
      "    vocabulary with 5430 words (includes start_word, end_word, unk_word)\n",
      "      start_id: 1\n",
      "      end_id: 2\n",
      "      unk_id: 5429\n",
      "      pad_id: 0\n"
     ]
    }
   ],
   "source": [
    "## build vocab\n",
    "if not os.path.isfile('vocab.txt'):\n",
    "    _ = tl.nlp.create_vocab(processed_capts, word_counts_output_file=VOC_FIR, min_word_count=1)\n",
    "else:\n",
    "    print(\"WARNING: vocab.txt already exists\")\n",
    "vocab = tl.nlp.Vocabulary(VOC_FIR, start_word=\"<S>\", end_word=\"</S>\", unk_word=\"<UNK>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * tokenized 81490 captions\n"
     ]
    }
   ],
   "source": [
    "## store all captions ids in list\n",
    "captions_ids = []\n",
    "try: # python3\n",
    "    tmp = captions_dict.items()\n",
    "except: # python3\n",
    "    tmp = captions_dict.iteritems()\n",
    "for key, value in tmp:\n",
    "    for v in value:\n",
    "        captions_ids.append( [vocab.word_to_id(word) for word in nltk.tokenize.word_tokenize(v)] + [vocab.end_id])  # add END_ID\n",
    "        # print(v)              # prominent purple stigma,petals are white inc olor\n",
    "        # print(captions_ids)   # [[152, 19, 33, 15, 3, 8, 14, 719, 723]]\n",
    "        # exit()\n",
    "captions_ids = np.asarray(captions_ids)\n",
    "print(\" * tokenized %d captions\" % len(captions_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_capt: this flower has bright purple  spiky petals  and greenish sepals below them \n",
      "nltk.tokenize.word_tokenize(img_capt): ['this', 'flower', 'has', 'bright', 'purple', 'spiky', 'petals', 'and', 'greenish', 'sepals', 'below', 'them']\n",
      "img_capt_ids: [6, 3, 7, 31, 18, 165, 4, 5, 318, 83, 374, 120]\n",
      "id_to_word: ['this', 'flower', 'has', 'bright', 'purple', 'spiky', 'petals', 'and', 'greenish', 'sepals', 'below', 'them']\n"
     ]
    }
   ],
   "source": [
    "## check\n",
    "img_capt = captions_dict[1][1]\n",
    "print(\"img_capt: %s\" % img_capt)\n",
    "print(\"nltk.tokenize.word_tokenize(img_capt): %s\" % nltk.tokenize.word_tokenize(img_capt))\n",
    "img_capt_ids = [vocab.word_to_id(word) for word in nltk.tokenize.word_tokenize(img_capt)]#img_capt.split(' ')]\n",
    "print(\"img_capt_ids: %s\" % img_capt_ids)\n",
    "print(\"id_to_word: %s\" % [vocab.id_to_word(id) for id in img_capt_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8149"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(captions_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * 8189 images found, start loading and resizing ...\n"
     ]
    }
   ],
   "source": [
    "## load images\n",
    "with tl.ops.suppress_stdout():  # get image files list\n",
    "    imgs_title_list = sorted(tl.files.load_file_list(path=img_dir, regx='^image_[0-9]+\\.jpg'))\n",
    "print(\" * %d images found, start loading and resizing ...\" % len(imgs_title_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "name = \"image_06734.jpg\"\n",
    "\n",
    "if int(name[6:11]) >= 6734 and int(name[6:11]) <= 6773:\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cseuser\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * loading and resizing took 117.95992136001587s\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "# time.sleep(10)\n",
    "# def get_resize_image(name):   # fail\n",
    "#         img = scipy.misc.imread( os.path.join(img_dir, name) )\n",
    "#         img = tl.prepro.imresize(img, size=[64, 64])    # (64, 64, 3)\n",
    "#         img = img.astype(np.float32)\n",
    "#         return img\n",
    "# images = tl.prepro.threading_data(imgs_title_list, fn=get_resize_image)\n",
    "images = []\n",
    "images_256 = []\n",
    "for name in imgs_title_list:\n",
    "    if int(name[6:11]) >= 6734 and int(name[6:11]) <= 6773:\n",
    "        continue\n",
    "    img_raw = scipy.misc.imread( os.path.join(img_dir, name) )\n",
    "    img = tl.prepro.imresize(img_raw, size=[64, 64])    # (64, 64, 3)\n",
    "    img = img.astype(np.float32)\n",
    "    images.append(img)\n",
    "    if need_256:\n",
    "        img = tl.prepro.imresize(img_raw, size=[256, 256]) # (256, 256, 3)\n",
    "        img = img.astype(np.float32)\n",
    "\n",
    "        images_256.append(img)\n",
    "# images = np.array(images)\n",
    "# images_256 = np.array(images_256)\n",
    "print(\" * loading and resizing took %ss\" % (time.time()-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_captions: 81490 n_images: 8149 n_captions_per_image: 10\n"
     ]
    }
   ],
   "source": [
    "n_images = len(captions_dict)\n",
    "n_captions = len(captions_ids)\n",
    "n_captions_per_image = len(lines) # 10\n",
    "\n",
    "print(\"n_captions: %d n_images: %d n_captions_per_image: %d\" % (n_captions, n_images, n_captions_per_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_images_train:8000 n_captions_train:80000\n",
      "n_images_test:149  n_captions_test:1490\n"
     ]
    }
   ],
   "source": [
    "captions_ids_train, captions_ids_test = captions_ids[: 8000*n_captions_per_image], captions_ids[8000*n_captions_per_image :]\n",
    "images_train, images_test = images[:8000], images[8000:]\n",
    "if need_256:\n",
    "    images_train_256, images_test_256 = images_256[:8000], images_256[8000:]\n",
    "n_images_train = len(images_train)\n",
    "n_images_test = len(images_test)\n",
    "n_captions_train = len(captions_ids_train)\n",
    "n_captions_test = len(captions_ids_test)\n",
    "print(\"n_images_train:%d n_captions_train:%d\" % (n_images_train, n_captions_train))\n",
    "print(\"n_images_test:%d  n_captions_test:%d\" % (n_images_test, n_captions_test))\n",
    "\n",
    "## check test image\n",
    "# idexs = get_random_int(min=0, max=n_captions_test-1, number=64)\n",
    "# temp_test_capt = captions_ids_test[idexs]\n",
    "# for idx, ids in enumerate(temp_test_capt):\n",
    "#     print(\"%d %s\" % (idx, [vocab.id_to_word(id) for id in ids]))\n",
    "# temp_test_img = images_train[np.floor(np.asarray(idexs).astype('float')/n_captions_per_image).astype('int')]\n",
    "# save_images(temp_test_img, [8, 8], 'temp_test_img.png')\n",
    "# exit()\n",
    "\n",
    "# ## check the first example\n",
    "# tl.visualize.frame(I=images[0], second=5, saveable=True, name='temp', cmap=None)\n",
    "# for cap in captions_dict[1]:\n",
    "#     print(cap)\n",
    "# print(captions_ids[0:10])\n",
    "# for ids in captions_ids[0:10]:\n",
    "#     print([vocab.id_to_word(id) for id in ids])\n",
    "# print_dict(captions_dict)\n",
    "\n",
    "# ## generate a random batch\n",
    "# batch_size = 64\n",
    "# idexs = get_random_int(0, n_captions_test, batch_size)\n",
    "# # idexs = [i for i in range(0,100)]\n",
    "# print(idexs)\n",
    "# b_seqs = captions_ids_test[idexs]\n",
    "# b_images = images_test[np.floor(np.asarray(idexs).astype('float')/n_captions_per_image).astype('int')]\n",
    "# print(\"before padding %s\" % b_seqs)\n",
    "# b_seqs = tl.prepro.pad_sequences(b_seqs, padding='post')\n",
    "# print(\"after padding %s\" % b_seqs)\n",
    "# # print(input_images.shape)   # (64, 64, 64, 3)\n",
    "# for ids in b_seqs:\n",
    "#     print([vocab.id_to_word(id) for id in ids])\n",
    "# print(np.max(b_images), np.min(b_images), b_images.shape)\n",
    "# from utils import *\n",
    "# save_images(b_images, [8, 8], 'temp2.png')\n",
    "# # tl.visualize.images2d(b_images, second=5, saveable=True, name='temp2')\n",
    "# exit()\n",
    "\n",
    "# import pickle\n",
    "from sklearn.externals import joblib\n",
    "def save_all(targets, file):\n",
    "    with open(file, 'wb') as f:\n",
    "        joblib.dump(targets, f)\n",
    "        # pickle.dump(targets, f)\n",
    "\n",
    "save_all(vocab, '_vocab.sav')\n",
    "save_all((images_train_256, images_train), '_image_train.sav')\n",
    "save_all((images_test_256, images_test), '_image_test.sav')\n",
    "save_all((n_captions_train, n_captions_test, n_captions_per_image, n_images_train, n_images_test), '_n.sav')\n",
    "save_all((captions_ids_train, captions_ids_test), '_caption.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
